# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SzNowTTsdY0rQV9NKfeD6VZ0LFMRNtef
"""

# Parkinson's Prediction App using Structured Inputs (Form + CSV + SHAP)

import streamlit as st
import pandas as pd
import numpy as np
import pickle
import shap
import xgboost as xgb
import matplotlib.pyplot as plt

# Load trained XGBoost model and scaler
# Ensure the model file exists at this path when deploying
try:
    with open("model/xgb_model.pkl", "rb") as f:
        model = pickle.load(f)
except FileNotFoundError:
    st.error("Model file 'model/xgb_model.pkl' not found. Please ensure the model is in the correct location.")
    st.stop() # Stop the app if the model is not found


# Page layout
st.title("Parkinson's Structured Data Predictor")
st.write("Upload a CSV or enter acoustic biomarker values manually to predict Parkinson's disease.")

# Feature names (from UCI dataset)
FEATURES = [
    "MDVP:Fo(Hz)", "MDVP:Fhi(Hz)", "MDVP:Flo(Hz)",
    "MDVP:Jitter(%)", "MDVP:Jitter(Abs)", "MDVP:RAP", "MDVP:PPQ",
    "Jitter:DDP", "MDVP:Shimmer", "MDVP:Shimmer(dB)", "Shimmer:APQ3",
    "Shimmer:APQ5", "MDVP:APQ", "Shimmer:DDA", "NHR", "HNR",
    "RPDE", "DFA", "spread1", "spread2", "D2", "PPE"
]

# Input option
option = st.radio("How would you like to provide input?", ["Manual Entry", "Upload CSV"])

input_df = pd.DataFrame()

if option == "Manual Entry":
    st.subheader("Manually Enter Feature Values")
    user_input = {}
    for feat in FEATURES:
        # Added a check to ensure number_input works with potentially large or small floats
        user_input[feat] = st.number_input(feat, value=0.0, format="%.6f") # Use a more precise format
    input_df = pd.DataFrame([user_input])

elif option == "Upload CSV":
    uploaded_file = st.file_uploader("Upload CSV with the same 22 features", type=["csv"])
    if uploaded_file:
        try:
            input_df = pd.read_csv(uploaded_file)
            # Optional: Add validation to check if uploaded CSV has the correct columns
            if not all(feat in input_df.columns for feat in FEATURES):
                st.error("Uploaded CSV does not contain all required features. Please check the column names.")
                input_df = pd.DataFrame() # Clear input_df to prevent prediction with wrong data
            else:
                 st.write("Preview of uploaded data:")
                 st.dataframe(input_df)
        except Exception as e:
             st.error(f"Error reading CSV file: {e}")
             input_df = pd.DataFrame() # Clear input_df on error


# Predict & show results
if not input_df.empty and len(input_df.columns) == len(FEATURES): # Ensure correct columns are present
    st.subheader("Model Prediction")
    try:
        prediction = model.predict(input_df)
        proba = model.predict_proba(input_df)[:, 1]

        for i in range(len(prediction)):
            label = "Parkinson's detected" if prediction[i] == 1 else "No Parkinson's"
            st.markdown(f"**Sample {i+1}:** {label}  ")
            st.markdown(f"Confidence: **{proba[i]*100:.2f}%**")

        # SHAP Explanation
        st.subheader("Explainability with SHAP")
        # Check if the model is suitable for TreeExplainer
        if isinstance(model, (xgb.XGBClassifier, xgb.XGBRegressor)):
            explainer = shap.TreeExplainer(model)
            # Ensure input_df columns match model expected features if possible
            # This might require training the model with feature names in mind or handling column order
            try:
                shap_values = explainer.shap_values(input_df[FEATURES]) # Ensure feature order
                # Plot summary for batch, or force plot for 1 sample
                if len(input_df) == 1:
                    st.set_option('deprecation.showPyplotGlobalUse', False)
                    shap.initjs()
                    # Use the correct SHAP values for the force plot (handle multi-output if necessary)
                    # For binary classification, shap_values can be a list [shap_values_class_0, shap_values_class_1]
                    # Often, shap_values for the positive class (index 1) is used.
                    if isinstance(shap_values, list):
                         # Use shap_values for the positive class (assuming it's binary classification)
                         shap_values_to_plot = shap_values[1][0] if len(shap_values) > 1 else shap_values[0][0]
                         expected_value_to_plot = explainer.expected_value[1] if isinstance(explainer.expected_value, np.ndarray) and len(explainer.expected_value) > 1 else explainer.expected_value
                         st.pyplot(shap.force_plot(expected_value_to_plot, shap_values_to_plot, input_df.iloc[0][FEATURES], matplotlib=True)) # Added matplotlib=True
                    else:
                         st.pyplot(shap.force_plot(explainer.expected_value, shap_values[0], input_df.iloc[0][FEATURES], matplotlib=True)) # Added matplotlib=True

                else:
                    st.set_option('deprecation.showPyplotGlobalUse', False)
                     # Use shap_values for the positive class for summary plot if binary classification
                    if isinstance(shap_values, list):
                        shap.summary_plot(shap_values[1], input_df[FEATURES], plot_type="bar")
                    else:
                         shap.summary_plot(shap_values, input_df[FEATURES], plot_type="bar")
                    st.pyplot(plt) # Explicitly display the plot

            except Exception as e:
                 st.error(f"Error generating SHAP explanation: {e}")

        else:
            st.warning("SHAP explanation is currently only supported for XGBoost models in this app.")

    except Exception as e:
         st.error(f"An error occurred during prediction or SHAP explanation: {e}")


# Footer
st.markdown("---")
st.caption("This app is for educational purposes and not a diagnostic tool.")